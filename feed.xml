<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://ayaankazerouni.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ayaankazerouni.github.io/" rel="alternate" type="text/html" /><updated>2022-09-19T11:29:17-07:00</updated><id>https://ayaankazerouni.github.io/feed.xml</id><title type="html">Ayaan M. Kazerouni</title><subtitle>Ayaan Kazerouni's personal website. Contains information about his research in computing education and software engineering, and  his hobbies and interests.
</subtitle><entry><title type="html">What makes CS students seek or avoid academic help resources?</title><link href="https://ayaankazerouni.github.io/posts/help-seeking-behaviours" rel="alternate" type="text/html" title="What makes CS students seek or avoid academic help resources?" /><published>2021-11-13T00:00:00-08:00</published><updated>2021-11-13T00:00:00-08:00</updated><id>https://ayaankazerouni.github.io/posts/help-seeking-behaviours</id><content type="html" xml:base="https://ayaankazerouni.github.io/posts/help-seeking-behaviours">&lt;p&gt;&lt;small&gt;
&lt;em&gt;This article was originally posted on &lt;a href=&quot;ayaankazerouni.medium.com&quot;&gt;my Medium blog&lt;/a&gt; on November 13, 2021.&lt;/em&gt;
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;This is an overview of the paper &lt;em&gt;&lt;a href=&quot;https://ayaankazerouni.github.io/publications#koli2021help-seeking&quot;&gt;Patterns of Academic Help-Seeking in Undergraduate Computing Students&lt;/a&gt;&lt;/em&gt;, appearing at the 2021 &lt;a href=&quot;https://www.kolicalling.fi/&quot;&gt;Koli Calling&lt;/a&gt; conference on computing education research. It was written by my student collaborator Augie Doebling and myself.&lt;/p&gt;

&lt;p&gt;Help-seeking is an expected phase in learning or problem-solving. The process involves a fair bit of self-regulatory skill; a learner must recognise that a problem or difficulty exists, assess whether they need help to surmount it, identify a help resource, and finally seek and process help.&lt;/p&gt;

&lt;p&gt;Undergraduate students tend to have a variety of academic help resources at their disposal. For example, taking Cal Poly as a typical example, students can seek help with their coursework from online sources, their peers, instructors, or the departmental peer tutoring centre.&lt;/p&gt;

&lt;p&gt;Much has been written about how students use individual resources, such as &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3291279.3339418&quot;&gt;TA office hours&lt;/a&gt; or &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3017680.3017745&quot;&gt;Piazza&lt;/a&gt;. But what we know holistically about how computing students navigate this array of resources is largely anecdotal. What resources do they tend to use most frequently? Does this differ for different demographic groups? What influences students to approach or avoid certain resources?&lt;/p&gt;

&lt;p&gt;We conducted a mixed-methods study to better understand the help-seeking behaviours of students in the CSSE department at Cal Poly.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Survey:&lt;/strong&gt; Distributed in a wide variety of Cal Poly CS courses, asking students about the frequency with which they accessed various help resources.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interviews:&lt;/strong&gt; A series of one-on-one interviews with students to learn the factors that influence their help-seeking decisions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We discussed the following resources (acronyms are for the figure that follows):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The instructor—in office hours (IN-OH), in class (IN-CL), or online (IN-OC)&lt;/li&gt;
  &lt;li&gt;The TA—in class (TA-CL) or online (TA-OC)&lt;/li&gt;
  &lt;li&gt;Peers—enrolled in the same class (PEC) or other classes (OP)&lt;/li&gt;
  &lt;li&gt;The peer tutoring centre (CSTC)&lt;/li&gt;
  &lt;li&gt;Online materials—specific to the course (OM-SC) or not specific to the course (OM-NSC)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;frequency-of-help-seeking&quot;&gt;Frequency of help-seeking&lt;/h2&gt;

&lt;p&gt;We received 138 survey responses about the frequency with which students accessed various help resources.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/help-seeking-behaviours/frequency.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/help-seeking-behaviours/frequency.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Frequency of accessing various help resources.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Students most frequently relied on &lt;strong&gt;online sources&lt;/strong&gt;, followed closely by their &lt;strong&gt;peers in class&lt;/strong&gt;.
They reported modest reliance on the &lt;strong&gt;instructor&lt;/strong&gt; for help, preferring to ask questions in class or online rather than going to office hours.&lt;/p&gt;

&lt;p&gt;Students did not report much use of &lt;strong&gt;course TAs&lt;/strong&gt; or the &lt;strong&gt;peer tutoring centre&lt;/strong&gt;.
The former may be because TAs at Cal Poly do not hold office hours like they might at other universities—there is typically much more contact with instructors than with TAs.&lt;/p&gt;

&lt;h2 id=&quot;trends-by-student-demographics&quot;&gt;Trends by student demographics&lt;/h2&gt;

&lt;p&gt;There was no difference in the overall frequency of help-seeking (across all resources) between men and women.
However, women reported turning to the “social” help resources more often than men did: they attended instructor office hours and accepted help from peers roughly &lt;em&gt;Once a Week&lt;/em&gt; compared to men’s &lt;em&gt;Every Few Weeks&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why might this be?&lt;/strong&gt; &lt;a href=&quot;https://bera-journals.onlinelibrary.wiley.com/doi/10.1002/rev3.3196&quot;&gt;Previous research&lt;/a&gt; has suggested that women tend to have a better attitude toward help-seeking than men do, viewing it more as a learning strategy and less as a sign of dependence.
It’s possible that students who are less inclined to seek help from social sources perceive some level of threat to their self-esteem from the act of seeking help.&lt;/p&gt;

&lt;p&gt;Finally, computing majors reported relying on their peers and online sources more often than did non-computing majors. No other notable patterns were observed for other resources and demographic groups (e.g., ethnicity, prior experience with computing, or academic progress).&lt;/p&gt;

&lt;h2 id=&quot;what-makes-students-approach-or-avoid-help-resources&quot;&gt;What makes students approach or avoid help resources?&lt;/h2&gt;

&lt;p&gt;Having discovered trends and correlations regarding frequency of accessing help resources, we turned to interviews to understand why students make the help-seeking decisions that they do.&lt;/p&gt;

&lt;p&gt;We asked students about the primary resources they turn to for academic help, the resources that they tend to avoid, and their reasons for both. A number of themes emerged from our qualitative analysis of interview transcripts.&lt;/p&gt;

&lt;p&gt;First, students tended to progress from informal to formal sources of help: a frequently reported pattern was the progression from &lt;em&gt;online sources&lt;/em&gt; to &lt;em&gt;peers&lt;/em&gt; to &lt;em&gt;instructors&lt;/em&gt;, where students only progressed to the next resource if the previous resource did not help surmount a problem.&lt;/p&gt;

&lt;p&gt;Below, I describe students’ reasons for using or not using different sources of academic help.&lt;/p&gt;

&lt;h3 id=&quot;online-sources&quot;&gt;Online sources&lt;/h3&gt;

&lt;p&gt;Reasons for using:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Ease of access:&lt;/em&gt; Just a few button presses away.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Concrete examples:&lt;/em&gt; Sites like StackOverflow were reported as being useful when one is trying to “get the ball rolling” with a new language or API, but less useful for obtaining concept knowledge about a topic.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reasons for not using:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Low signal-to-noise ratio:&lt;/em&gt; It takes experience and expertise to sort through the wealth of information available through a simple Google search. Students reported that online resources became more useful to them as they became more experienced programmers, but were overwhelming when they were first learning programming.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Interestingly, some students did not report online sources in their help-seeking process until specifically asked about them; they did not view it as seeking help, but rather viewed it as helping themselves.&lt;/p&gt;

&lt;h3 id=&quot;peers&quot;&gt;Peers&lt;/h3&gt;

&lt;p&gt;Reasons for using:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Ease of access:&lt;/em&gt; Peers are just a text message away.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Stress-free help:&lt;/em&gt; Peers tend to not judge one’s lack of knowledge. There is less (perceived or actual) “threat” from seeking help from a peer than there is from, say, course staff.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reasons for not using:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Lack of a peer network:&lt;/em&gt; First-year students, transfer students, or students from historically minoritised groups may not have access to a solid network of peers.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Fear of academic dishonesty:&lt;/em&gt; Students worried about accidentally breaking rules related to academic dishonesty if they worked too closely with peers. For example, they reported being hesitant to speak in detail about (or ask others about) their programming projects.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reasons-for-using&quot;&gt;Reasons for using&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Depth of content knowledge:&lt;/em&gt; Instructors are knowledgeable about their subject matter, and often provide the definitive help needed to surmount a problem.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Depth of pedagogical content knowledge:&lt;/em&gt; Instructors have seen many of the common bugs, pitfalls, and strategies used for their assignments, and are best suited to help when a student is struggling.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Forming a connection:&lt;/em&gt; Synchronous office hours helped some students form connections with their instructors, making help-seeking and learning a stress-free experience.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reasons for not using:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Tacit knowledge:&lt;/em&gt; Instructors often have an “expert blind spot”, and the help they give often assumes knowledge that the student (1) doesn’t have, or (2) can’t automatically transfer to their current problem.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Approachability:&lt;/em&gt; Students reported that instructors could often be intimidating (or worse, demeaning) when they were asked for help. Importantly, many students reported that poor experiences with one instructor made them less likely to seek help from any instructors in the future.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;recommendations-for-cs-instructors-or-departments&quot;&gt;Recommendations for CS instructors or departments&lt;/h2&gt;

&lt;p&gt;Based on students’ responses, we close with some recommendations for reducing the barriers to seeking academic help.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Online sources&lt;/strong&gt;—In early courses, model a process for finding information online and identifying high-quality sources. This need not be limited to StackOverflow answers; it can also include official documentation for programming languages or APIs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Peers&lt;/strong&gt;—Feature collaborative work more prominently in early courses. This could include team projects as well as teaching practices like peer instruction or think-pair-share. Featuring more collaborative work in earlier courses would provide students access to peers to work with “legally”, and would help them form peer networks that could last into future courses.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Instructors&lt;/strong&gt;—Ensure that classrooms and office hours are welcoming spaces. Instructors play a massive role in shaping the overall climate of a classroom or department. Being cognizant of this outsized impact and taking steps to ensure a welcoming atmosphere could have huge positive implications for student success.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">This article was originally posted on my Medium blog on November 13, 2021.</summary></entry><entry><title type="html">Fast and Accurate Incremental Feedback for Students’ Software Tests Using Selective Mutation Analysis</title><link href="https://ayaankazerouni.github.io/posts/fast-accurate-mutation-feedback" rel="alternate" type="text/html" title="Fast and Accurate Incremental Feedback for Students’ Software Tests Using Selective Mutation Analysis" /><published>2021-03-17T00:00:00-07:00</published><updated>2021-03-17T00:00:00-07:00</updated><id>https://ayaankazerouni.github.io/posts/fast-accurate-mutation-feedback</id><content type="html" xml:base="https://ayaankazerouni.github.io/posts/fast-accurate-mutation-feedback">&lt;p&gt;&lt;small&gt;
&lt;em&gt;This post originally appeared on &lt;a href=&quot;ayaankazerouni.github.io&quot;&gt;my Medium blog&lt;/a&gt; on March 17, 2021.&lt;/em&gt;
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;This is an overview of the paper &lt;em&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0164121221000029&quot;&gt;Fast and Accurate Incremental Feedback for Students’ Software Tests Using Selective Mutation Analysis&lt;/a&gt;&lt;/em&gt;, published in the Journal of Systems and Software. The paper is freely available. My co-authors were &lt;a href=&quot;https://davisjam.github.io&quot;&gt;Jamie Davis&lt;/a&gt;, &lt;a href=&quot;https://arinjoy-basak.github.io/&quot;&gt;Arinjoy Basak&lt;/a&gt;, &lt;a href=&quot;https://people.cs.vt.edu/shaffer&quot;&gt;Cliff Shaffer&lt;/a&gt;, &lt;a href=&quot;https://people.cs.vt.edu/fservant&quot;&gt;Francisco Servant&lt;/a&gt;, and &lt;a href=&quot;https://people.cs.vt.edu/edwards&quot;&gt;Steve Edwards&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;TL;DR: Use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt; and arithmetic operator deletion (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AOD&lt;/code&gt;) mutation operators for fast and reliable mutation analysis.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Feedback about students’ software tests is often generated using code coverage criteria (like statement or condition coverage). These can be unreliable given that code coverage is satisfied simply by the execution of the code-under-test, and not by the actual assertions in the tests.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Mutation analysis&lt;/em&gt; is a stronger but much more costly criterion for measuring the adequacy of software tests. In this paper, we evaluated the feasibility of existing approaches to mutation analysis for producing automated feedback for student-written software tests. After finding that existing approaches were infeasible, we proposed new approaches for fast and accurate mutation analysis. Finally, we evaluated our proposed approaches for validity on an external dataset of open-source codebases, and report that our results may be generalisable beyond our educational context.&lt;/p&gt;

&lt;p&gt;This post is of interest to Computer Science educators interested in giving students useful feedback about their software testing, and to software engineers interested in using mutation analysis to help them write stronger software tests.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Software testing is important. As it is increasingly incorporated into undergraduate programming courses, teachers are giving students feedback not only about the correctness of their programs, but also about the quality of their software tests.&lt;/p&gt;

&lt;p&gt;Much of this feedback is based on assessments of test adequacy, most commonly &lt;em&gt;code coverage criteria&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Code coverage criteria are satisfied when structural elements (statements, conditions, etc.) of a program are exercised by a test suite at least once. For example, under statement coverage, the test suite’s adequacy is measured as the percentage of program constructs that are executed by the tests. Code coverage is &lt;strong&gt;fast to compute&lt;/strong&gt; and &lt;strong&gt;amenable to incremental feedback&lt;/strong&gt;. But it can be &lt;strong&gt;unreliable&lt;/strong&gt;, because the criterion is not bound to the &lt;em&gt;assertions&lt;/em&gt; in software tests, just to the underlying code that is executed.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Mutation_testing&quot;&gt;Mutation analysis&lt;/a&gt;&lt;/em&gt; is a far more reliable option. Small changes (&lt;em&gt;mutations&lt;/em&gt;) are made to the target program, creating incorrect variants called &lt;em&gt;mutants&lt;/em&gt;. The test suite is run against these mutants, and its adequacy is measured as the percentage of mutants that are detected by the test suite (i.e., by a failing test). The different kinds of mutations you could make are called &lt;em&gt;mutation operators&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Mutation analysis subsumes code coverage as a test adequacy criterion&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, and has been shown to be a &lt;strong&gt;reliable measurement of test adequacy&lt;/strong&gt;. It can also be used to produce &lt;strong&gt;incremental feedback&lt;/strong&gt;: I don’t need a student to have finished a project to give them feedback about their tests.&lt;/p&gt;

&lt;h2 id=&quot;reducing-the-cost-of-mutation-analysis&quot;&gt;Reducing the cost of mutation analysis&lt;/h2&gt;
&lt;p&gt;Unfortunately, mutation analysis can be &lt;strong&gt;prohibitively expensive&lt;/strong&gt; computationally. The number of mutants produced for even a moderately sized project (~1 KLoC) can reach well into the thousands. Running the test suite for each of these mutants can take several minutes, sometimes hours.&lt;/p&gt;

&lt;p&gt;Significant research effort has been devoted to reducing this cost. One such approach is &lt;em&gt;selective mutation&lt;/em&gt;. The main idea behind selective mutation is to select a subset of mutation operators that give you the best “bang for your buck”. That is, out of the &lt;strong&gt;Full&lt;/strong&gt; set of mutation operators (all available operators) you want a subset that gives you a reliable test adequacy score — one that is close to the “true” thoroughness of your tests — while producing a small number of mutants.&lt;/p&gt;

&lt;p&gt;Numerous such operator subsets have been proposed. One key example is the &lt;strong&gt;Deletion&lt;/strong&gt; set, originally proposed by Roland Untch&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; and reified by Jeff Offutt and colleagues&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Deletion operators create mutants by systematically deleting program constructs. This simple mutation scheme results in significantly fewer mutants. For example, if we were to remove the arithmetic operator in the expression &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a + b&lt;/code&gt;, we just create two mutants: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;b&lt;/code&gt;. This is in contrast to the four mutants that would be created by arithmetic operator &lt;strong&gt;replacement&lt;/strong&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a — b, a / b, a * b, a % b&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We used the mutation analysis system &lt;a href=&quot;https://pitest.org&quot;&gt;PIT&lt;/a&gt;, which is built for speed and scalability. We approximated the Deletion set in PIT to be:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RemoveConditionals&lt;/strong&gt;, which replaces conditional statements with boolean literals, i.e., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt; (forcing the execution of the “if” branch) or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt; (forcing execution of the “else” branch)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Arithmetic operator deletion (AOD)&lt;/strong&gt;. E.g., the expression &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a + b&lt;/code&gt; would produce the mutants &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;b&lt;/code&gt;, removing the arithmetic operator (and one operand) entirely.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;NonVoidMethodCalls&lt;/strong&gt;, which replaces calls to non-void methods with the default values for the specific return type. That is, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int&lt;/code&gt;-returning method calls would be replaced with 0, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Object&lt;/code&gt;-returning method calls would be replaced with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null&lt;/code&gt;, etc.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;VoidMethodCalls&lt;/strong&gt;, which simply removes calls to methods that do not return anything.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MemberVariable&lt;/strong&gt;, which removes assignments to instance variables.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ConstructorCalls&lt;/strong&gt;, which replaces calls to constructors with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;fast-and-accurate-mutation-based-feedback&quot;&gt;Fast and accurate mutation-based feedback&lt;/h2&gt;

&lt;p&gt;Students in our courses are allowed and encouraged to make many incremental submissions to the auto-grader to help them ensure they’re on the right track. As deadlines approach, this can result in bursty traffic placing enormous load on the server.&lt;/p&gt;

&lt;p&gt;We ran mutation analysis on 1389 submissions in two courses in the CS program at Virginia Tech: a second year course on Software Design and Data Structures, and a third-year course on Data Structures and Algorithms. Projects were implemented in Java, and students were required to turn in &lt;a href=&quot;https://junit.org&quot;&gt;JUnit&lt;/a&gt; test suites with their project submissions.&lt;/p&gt;

&lt;p&gt;Analysis was conducted on a machine with similar specifications as the one serving our auto-grading infrastructure, &lt;a href=&quot;https://web-cat.github.io&quot;&gt;Web-CAT&lt;/a&gt;. We did not eliminate &lt;em&gt;equivalent mutants&lt;/em&gt; from our data-set. These cannot be automatically identified, which makes eliminating them from our corpus a daunting prospect.&lt;/p&gt;

&lt;p&gt;We grouped submissions by source lines of code (SLoC), ranging from ~150 LoC to ~1200 LoC.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/fast-accurate-mutation-feedback/submission-groups.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/fast-accurate-mutation-feedback/submission-groups.png&quot; alt=&quot;A histogram showing project groupings. Group 1, with submissions smaller than 341 lines of code, contains 672 submissions. Group 2, with submissions smaller than 666 lines of code, contains 353 submissions. Group 3, with submissions smaller than 1097 lines of code, contains 245 submissions. Group 4, with the largest submissions, contains 119 lines of code.&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Groups of submissions based on source lines of code (SLoC). Dashed lines indicate group boundaries.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;For each operator subset, we looked at&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Computational cost:&lt;/strong&gt; the running time in seconds (i.e., how long would a student spend twiddling their thumbs waiting for feedback?) and the number of mutants produced per thousand lines of code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Accuracy&lt;/strong&gt; at predicting coverage under the Full set. That is, if mutants under a given subset are killed by the test suite, how likely is it that the test suite will also kill mutants under the Full set?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Preliminary results showed that comprehensive mutation (i.e., using all available mutation operators) was certainly too slow for our purposes. For submissions in the larger submissions groups, even the Deletion set took too long (nearly a minute) to produce feedback.&lt;/p&gt;

&lt;p&gt;That said, the Deletion set showed promise. As Offutt and friends reported, it produces a remarkably good approximation of mutation adequacy at a fraction of the computational cost of comprehensive mutation.&lt;/p&gt;

&lt;p&gt;Can we reduce this cost further?&lt;/p&gt;

&lt;h2 id=&quot;reducing-the-cost-of-the-deletion-set&quot;&gt;Reducing the cost of the Deletion set&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Do we need all six Deletion operators to make a useful approximation of mutation adequacy?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We used forward selection to determine an appropriate ordering of Deletion operators, set up as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Dependent variable:&lt;/strong&gt; Mutation coverage using all available operators&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Independent variables:&lt;/strong&gt; Mutation coverage under each individual Deletion operator&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Procedure:&lt;/strong&gt; Starting from an empty set of operators, we iteratively added the single operator that most improved a model predicting comprehensive mutation coverage, stopping when all Deletion operators were included or when the model could no longer improve.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All Deletion operators were included, in the following order: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals, AOD, NonVoidMethodCalls, VoidMethodCalls, MemberVariable, ConstructorCalls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Then, we examined the cost and effectiveness of incremental slices of this ordering:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;1-operator subset&lt;/strong&gt;, containing only &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;2-operator subset&lt;/strong&gt;, containing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AOD&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;3-operator subset&lt;/strong&gt;, containing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AOD&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NonVoidMethodCalls&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;…continued until the entire Deletion set is included&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;result&quot;&gt;Result&lt;/h2&gt;
&lt;p&gt;We found that most of the Deletion set’s effectiveness comes from the first two operators, i.e., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AOD&lt;/code&gt;. Inclusion of additional operators drives up the cost, but with little improvement to accuracy.&lt;/p&gt;

&lt;figure class=&quot;wide&quot;&gt;

  &lt;a href=&quot;/assets/posts/images/fast-accurate-mutation-feedback/inc-subsets.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/fast-accurate-mutation-feedback/inc-subsets.png&quot; alt=&quot;Four subplots, each with four box plots showing operator subset cost, and line plots showing operator subset accuracy.&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;The cost and accuracy of our proposed incremental subsets of operators. For each subplot, the left axis represents cost (# mutants per KSLoC) and the right axis represents accuracy (Adjusted R² predicting Full coverage) Y-axes are shared across subplots. Inline text at the bottom of the charts indicates the median running time on our server.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In the figure above,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Each column represents a single submission group,&lt;/li&gt;
  &lt;li&gt;Each box plot represents the cost distribution of a subset for that submission group, in mutations-per-thousand-LoC,&lt;/li&gt;
  &lt;li&gt;Each blue dot represents the percent of variance in comprehensive mutation that is explained by that subset for the given submission group&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can see that for submission groups 2–4, the cost drops precipitously from Deletion \(\to\) 3-op \(\to\) 2-op \(\to\) 1-op, while the accuracy stays more or less the same. For the smaller submissions in group 1, it’s possible that they simply do not provide enough opportunities for mutation to take place, so accuracy takes a huge hit for each mutation operator that is excluded.&lt;/p&gt;

&lt;p&gt;Some key takeaways:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The RemoveConditionals operator, by itself, is enormously effective&lt;/strong&gt; for the larger, more complex submissions, pushing 90% adjusted \(R^2\) for group 4 submissions (see the 1-op box plot in the rightmost subplot). For groups 2 and 3, it still does pretty well, but requires the inclusion of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AOD&lt;/code&gt; operator to cross the 90% threshold.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Which operators are most useful seems tied to the project itself.&lt;/strong&gt; It is no surprise that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt; does not do so well for the group 1 submissions: they are of minimal cyclomatic complexity, meaning they contain few conditional statements. Including &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AOD&lt;/code&gt; substantially improves the approximation, because these projects tend to focus more on arithmetic operations and less on data structure implementations (in contrast to the submissions found in the Data Structures and Algorithms course).&lt;/p&gt;

&lt;h2 id=&quot;validating-our-results&quot;&gt;Validating our results&lt;/h2&gt;
&lt;p&gt;At this point, it looks like mutation analysis using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals+AOD&lt;/code&gt; are feasible options for giving our students fast and reliable feedback about their test suites.&lt;/p&gt;

&lt;p&gt;The question now is: are these results generally useful? Or are they specific to submissions produced by students in our courses?&lt;/p&gt;

&lt;p&gt;We turn to a data-set&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; released by Marinos Kintis and colleagues containing programs, mutants, and mutation-adequate test suites, drawn from 6 open-source Java projects.&lt;/p&gt;

&lt;p&gt;Using this dataset, we evaluated the cost and effectiveness of the Deletion, 3-op, 2-op, and 1-op subsets.&lt;/p&gt;

&lt;p&gt;For each subset, we examined:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Reliability&lt;/strong&gt;, measured by creating a subset-adequate test suite, and seeing how it held up using all possible mutants. In other words, if a developer stopped testing when they satisfied a subset, how thorough would their test suite be under comprehensive mutation?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cost&lt;/strong&gt;, measured as the percentage of all possible mutants that were created by the subset.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kintis et al. also hand-marked equivalent mutants in their published data-set. This gives us an opportunity to test our operator subsets in the absence of these mutants, addressing a limitation present in our analysis of our students’ submissions.&lt;/p&gt;

&lt;h2 id=&quot;result-1&quot;&gt;Result&lt;/h2&gt;
&lt;p&gt;Results were largely in agreement with the study described above.&lt;/p&gt;

&lt;p&gt;In terms of &lt;strong&gt;reliability&lt;/strong&gt;, it appeared that the incremental subsets were nearly as effective as the entire Deletion set, with the 3-op subset (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NonVoidMethodCalls&lt;/code&gt; and beyond) bringing diminishing returns. This is similar to our original results.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/fast-accurate-mutation-feedback/val-mutation-score.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/fast-accurate-mutation-feedback/val-mutation-score.png&quot; alt=&quot;Four box-plots shows the Mutation score of the Deletion, 3-op, 2-op, and 1-op subsets. The median mutation scores are 0.95, 0.95, 0.95, and 0.9, respectively.&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Mutation coverage: Proportion of Full mutants detected by the subset-adequate test suite.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The &lt;strong&gt;cost&lt;/strong&gt; naturally decreases in the order Deletion \(\to\) 3-op \(\to\) 2-op \(\to\) 1-op.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/fast-accurate-mutation-feedback/val-cost.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/fast-accurate-mutation-feedback/val-cost.png&quot; alt=&quot;The cost in terms of the proportion of mutants produced by the Deletion, 3-op, 2-op, and 1-op subsets. The median proportions are around 0.155, 0.148, 0.110, 0.060, respectively.&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Computational cost: Number of mutants produced by each subset, expressed as a proportion of the Full number of mutants.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;final-remarks&quot;&gt;Final remarks&lt;/h2&gt;
&lt;p&gt;These results suggest that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt; operator is a feasible option for fast and accurate mutation analysis. And this makes sense, because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveConditionals&lt;/code&gt; can be thought of as a stronger form of condition coverage—only instead of simply requiring that all conditions evaluate to true and false at least once, it is satisfied when the tests depend on the conditions evaluating to true or false at least once. The difference is subtle, but results in much more thorough tests when used as a basis for measuring test adequacy.&lt;/p&gt;

&lt;p&gt;Including the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AOD&lt;/code&gt; operator provides an even stronger criterion, and it especially useful when the code-under-test has few logical branches. Including further Deletion operators drives up the cost but without improvements in effectiveness.&lt;/p&gt;

&lt;p&gt;It remains to be seen whether mutation-based testing feedback using one or both of these operators helps students to produce stronger test suites. Future work should involve evaluating mutation analysis for its utility as a device for practice and feedback with software testing.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://cs.gmu.edu/media/techreports/ISSE-TR-96-01.pdf&quot;&gt;Offutt, 1996&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/1566445.1566540&quot;&gt;Untch, 2009&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/6823861&quot;&gt;Delamaro, Offutt, &amp;amp; Ammann, 2014&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://pages.cs.aueb.gr/~kintism/papers/scam2016/&quot;&gt;Kintis et al., 2016&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">This post originally appeared on my Medium blog on March 17, 2021.</summary></entry><entry><title type="html">Explicit Milestones on Intermediate Software Projects are Pretty Not Bad</title><link href="https://ayaankazerouni.github.io/posts/explicit-project-milestones" rel="alternate" type="text/html" title="Explicit Milestones on Intermediate Software Projects are Pretty Not Bad" /><published>2020-10-14T00:00:00-07:00</published><updated>2020-10-14T00:00:00-07:00</updated><id>https://ayaankazerouni.github.io/posts/explicit-project-milestones</id><content type="html" xml:base="https://ayaankazerouni.github.io/posts/explicit-project-milestones">&lt;p&gt;&lt;small&gt;
&lt;i&gt;This article was originally posted on &lt;a href=&quot;ayaankazerouni.medium.com&quot;&gt;my Medium blog&lt;/a&gt; on October 14, 2020.&lt;/i&gt;
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is an overview of the research paper “&lt;strong&gt;&lt;a href=&quot;/publications#sigcse2021milestones&quot;&gt;The Impact of Programming Project Milestones on Procrastination, Project Outcomes, and Course Outcomes&lt;/a&gt;&lt;/strong&gt;” by &lt;a href=&quot;https://people.cs.vt.edu/shaffer&quot;&gt;Cliff Shaffer&lt;/a&gt; and myself, appearing at SIGCSE 2021.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Undergraduate CS students often lack experience working on large, un-scaffolded, and long-running software projects. When they encounter such projects for the first time in intermediate programming courses, they do so without any procedural knowledge for how to go about tackling them. As a result, many of them struggle to complete these projects on time or correctly. As educators, we can do a better job supporting students as they approach these projects.&lt;/p&gt;

&lt;p&gt;We started giving students explicit project milestones with intermediate deadlines, to go with software project specifications in a third-year Data Structures course. The goal is to give students guided practice with project decomposition, time management, and successful project completion.&lt;/p&gt;

&lt;p&gt;In a quasi-experiment to determine the impact that milestones had on timeliness, project correctness, and course outcomes, we found that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Milestones had a considerably strong effect on timeliness, reducing the rate of late submissions by nearly 30%&lt;/li&gt;
  &lt;li&gt;Students with milestones produced projects with slightly higher correctness than students without milestones&lt;/li&gt;
  &lt;li&gt;Milestones had little effect on frequencies of course outcomes, with its positive effects limited to the “students in the middle”. Unfortunately, just as many students failed the course, and just as many students withdrew from the course, with or without milestones.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Read on for more information.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Students in intermediate programming courses often work on large, un-scaffolded, and relatively long-running software projects. These tend to be larger and more complex than projects they have worked on in the past, and consequentially bring with them a set of self-regulatory challenges that the students may be ill-equipped to deal with. No longer are assignment specifications given as easy-to-approach bullet-lists of requirements. Instead, they’re presented with a “wall of prose” from which they must extract requirements, plan their development, and get to work.&lt;/p&gt;

&lt;p&gt;An expert software developer has the domain-specific self-regulatory skills to tackle such a project. She can decompose such a project into sub-goals and budget the time needed to tackle each one. Novices, however, are often unable to do this decomposition themselves, and are famously poor at estimating the time needed for a development task &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. So instead, they are left facing the project with no clear place to start, low self-efficacy regarding their ability to finish, and not much prior experience from which to draw strategies or confidence.&lt;/p&gt;

&lt;p&gt;A common manifestation of students’ ill-preparedness to approach these projects is procrastination, the “quintessential self-regulatory failure”&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. According to Science, there are many reasons for procrastination. Chief among them are task-related reasons. For example, we know that people are more likely to procrastinate:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;when the task’s outcome is expected farther in the future&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;,&lt;/li&gt;
  &lt;li&gt;when they have low expectancy of successfully completing the task&lt;sup id=&quot;fnref:3:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, and&lt;/li&gt;
  &lt;li&gt;when the task offers numerous junctures for decision-making (e.g., the student doesn’t know where to start)&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Can we use this knowledge to reduce the frequency of procrastination on these projects and ameliorate its negative effects? I previously wrote about the pervasive and pernicious nature of procrastination in this context—students start late, work late, and finish late, often resulting in degraded project outcomes.&lt;/p&gt;

&lt;p&gt;In this post, I describe a simple classroom intervention that helped reduce the rate of late submissions on programming projects by about 30%, and helped improve class performance in the intermediate Data Structures and Algorithms (DSA) course at Virginia Tech.&lt;/p&gt;

&lt;h2 id=&quot;explicit-project-milestones&quot;&gt;Explicit project milestones&lt;/h2&gt;

&lt;p&gt;Our intermediate DSA course involves three to four programming projects, each of which is worked on for about a month. Each project requires students to build one or more interacting data structures—for example, a hash table or a PR quad-tree. Projects are un-scaffolded (no starter code) and students are free to design their own solutions. They are allowed to make as many submissions as they like to our auto-grader, which tests their solutions using acceptance tests written by the course staff.&lt;/p&gt;

&lt;p&gt;Unfortunately, these projects usually have distressingly high rates of late submissions and failing grades, and about 25–30% of students either fail or withdraw from the course.&lt;/p&gt;

&lt;p&gt;We believe that poor self-regulation and project management (often manifesting as procrastination) may be a significant contributor to these poor outcomes. Therefore, we instituted explicit project milestones—we broke down projects into sub-tasks that students needed to complete by intermediate deadlines. We expected to observe reduced procrastination stemming from&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;outcomes that are too far in the future to be valued in the present,&lt;/li&gt;
  &lt;li&gt;students not being able to decompose a large engineering task into manageable sub-tasks, and&lt;/li&gt;
  &lt;li&gt;low expectancy of success, because completing each successive sub-task is likely to increase the student’s self-efficacy regarding the larger overarching task&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The milestones themselves were pretty straightforward, and checkable using our auto-grading infrastructure. For any given data structure (or database made up of interacting data structures), they were as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Milestone 1&lt;/strong&gt;: Make a first submission to the auto-grader (speaking as a former instructor for this course, this was surprisingly effective at making students start thinking about the project early)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Milestone 2&lt;/strong&gt;: Complete the insertion operation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Milestone 3&lt;/strong&gt;: Complete the search and update operations&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Final submission&lt;/strong&gt;: Complete the removal operation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Done in that order, the removal operation is completed last. This is good because removal is often the hardest-to-implement operation in many data structures, involving complex structural rearrangements (e.g., re-ordering a binary search tree, or re-balancing a B+ tree). Our hope is that the experience of successfully completing the other, simpler operations a week or two earlier helps build the student’s self-efficacy regarding the more difficult sub-task ahead.&lt;/p&gt;

&lt;h2 id=&quot;how-helpful-were-the-milestones&quot;&gt;How helpful were the milestones?&lt;/h2&gt;
&lt;p&gt;We instituted Milestones in the Spring of 2016. We are interested in knowing if the milestones had any impact on procrastination, project outcomes, or course outcomes. So we compared outcomes in the “milestones semester” (Spring 2016) with outcomes in a “no milestones semester”—Fall 2013. In Fall 2013, the course was taught by the same instructor (Cliff), and the projects were of comparable difficulty. In terms of LoC and cyclomatic complexity, there were no differences between project submissions in the two semesters.&lt;/p&gt;

&lt;p&gt;We measured differences in terms of timeliness, project correctness, and course outcomes. I present a high-level overview of our results below. More details can be found in the paper.&lt;/p&gt;

&lt;h3 id=&quot;timeliness&quot;&gt;Timeliness&lt;/h3&gt;

&lt;p&gt;Milestones were pretty effective! We measured the rate of late submissions and the time of project completion for the two semesters. We checked for differences between the two semesters as well as differences within the milestones semester based on the number of milestones completed.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The rate of late submissions dropped from 41% with milestones to 12% without milestones&lt;/li&gt;
  &lt;li&gt;Within the treatment semester, students who completed 0 or 1 milestones tended to finish on the day of or after the deadline, while students who completed 2 or 3 milestones tended to finish their projects a day or more before the deadline&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Results are summarised in the figure below.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/explicit-project-milestones/completion-time-milestone-group.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/explicit-project-milestones/completion-time-milestone-group.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Completion times (in terms of hours before or after the deadline) with and without milestones. Whiskers are the 10th and 90th percentiles. Outliers beyond these percentiles are omitted.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;project-correctness&quot;&gt;Project correctness&lt;/h3&gt;

&lt;p&gt;As I stated above, a lack of self-efficacy or discipline-specific procedural knowledge may be contributing to students’ poor outcomes on these projects. In addition to late submissions, students are prone to submitting incorrect or inadequately tested solutions. So we checked to see if milestones had any impact on project correctness.&lt;/p&gt;

&lt;p&gt;Project correctness was defined as the percentage of instructor-written acceptance tests that the student’s submission passed. We checked for differences in correctness between submissions in the two semesters, and differences within the milestones semester based on the number of milestones completed.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The mean correctness score increased slightly, from 72% (sd = 20%) without milestones to 76% (sd = 21%) with milestones&lt;/li&gt;
  &lt;li&gt;Students who completed 2 or more milestones tended to produce projects with higher correctness than those who completed fewer milestones&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/explicit-project-milestones/correctness-milestone-group.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/explicit-project-milestones/correctness-milestone-group.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Correctness scores with and without milestones&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;course-outcomes&quot;&gt;Course outcomes&lt;/h3&gt;
&lt;p&gt;Having seen that milestones had a positive impact on timeliness and correctness, we now turn to course outcomes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;First&lt;/strong&gt;, we examine the pass, fail, and withdrawal rates in the course.&lt;/p&gt;

&lt;p&gt;Students at our institution tend to find this course challenging, and it is common to see 25–30% of students withdraw from the course or fail to achieve a grade that will let them progress on to subsequent courses.&lt;/p&gt;

&lt;p&gt;Success in the course is largely driven by success on the projects, and students may be withdrawing from the course based on early bad outcomes. So did milestones help to brighten this gloomy picture?&lt;/p&gt;

&lt;p&gt;Sadly, no.&lt;/p&gt;

&lt;p&gt;We first checked for differences in the frequency of the following course outcomes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Pass&lt;/em&gt;, where the student achieved a grade that let them move on in the major&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Fail&lt;/em&gt;, where the student completed the course, but would need to take it again before moving on&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Withdraw&lt;/em&gt;, where the student did not complete the course&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- [&lt;sup id='1-source'&gt;1&lt;/sup&gt;](#1-sink) --&gt;

&lt;p&gt;We didn’t find any differences in these outcomes between the two semesters. This is apparent in the figure below.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/explicit-project-milestones/outcomes.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/explicit-project-milestones/outcomes.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Milestones seem not to have affected course Pass, Fail, and Withdraw rates.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Next&lt;/strong&gt;, we explored the impact that milestones had on frequencies of final course grades, which were a composite of project performance, exam performance, and performance on mastery-based homework assignments. Differences in these frequencies could indicate the specific groups of students who were helped or not helped by the milestones intervention.&lt;/p&gt;

&lt;p&gt;We examined differences in the frequencies of &lt;em&gt;A&lt;/em&gt;, &lt;em&gt;B&lt;/em&gt;, &lt;em&gt;C&lt;/em&gt;, &lt;em&gt;D&lt;/em&gt;, and &lt;em&gt;F&lt;/em&gt; grades between the two semesters. Results are in the figure below.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/explicit-project-milestones/grades.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/explicit-project-milestones/grades.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Final course grades with and without milestones.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;More students received &lt;em&gt;A&lt;/em&gt; grades in the milestones semester (54%) than in the semester without milestones (34%). In contrast, fewer students received &lt;em&gt;B&lt;/em&gt; grades in the milestones semester (20%) than in the semester without milestones (38%). We found no other differences.&lt;/p&gt;

&lt;p&gt;Taken together, the results above suggest that the positive effects of the milestones were more pronounced for the students “in the middle”: many &lt;em&gt;B&lt;/em&gt;-level students became &lt;em&gt;A&lt;/em&gt;-level students, but unfortunately the &lt;em&gt;C&lt;/em&gt;-, &lt;em&gt;D&lt;/em&gt;-, and &lt;em&gt;F&lt;/em&gt;-level students continued to struggle in the course.&lt;/p&gt;

&lt;p&gt;It seems as though this intervention, while helpful, failed to assist the most vulnerable students in the course. Other supports and instructional changes are needed to help those students.&lt;/p&gt;

&lt;h2 id=&quot;what-did-students-think-of-the-milestones&quot;&gt;What did students think of the milestones?&lt;/h2&gt;
&lt;p&gt;We included this question in an informal end-of-term survey:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;How helpful did you find the Milestones in completing your programming projects on time? Please explain why you gave this response.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;75% of students found the milestones to be Helpful or Very helpful. Students mentioned that milestones helped them avoid procrastination, encouraged them along the path to project completion, and helped them decompose the project.&lt;/p&gt;

&lt;p&gt;15% of students were Neutral about the milestones. These students indicated that they were already on track without the milestones.&lt;/p&gt;

&lt;p&gt;10% of students who found milestones to be Not helpful or Not at all helpful, and indicated that milestones were stressful and sometimes interfered with their existing project development plans.&lt;/p&gt;

&lt;p&gt;We interpret the above to mean that perceptions of the milestones were largely positive, though some students found them to be unnecessary or stressful.&lt;/p&gt;

&lt;p&gt;Note that this was just a single question in a survey — this is not a detailed qualitative analysis of students’ attitudes toward assigned project milestones.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Aside: I’ve used milestones when teaching this course over the Summer session, and it may have been a blunder in that context. Summers tend to be intense, squeezing 15 weeks of material into 6 weeks of daily instruction. Month-long projects are 2-week projects. It’s hard to space out milestones appropriately in such a short timeframe (avoiding weekend deadlines, etc.). I had a student mention that they worked a job during the week, and did coursework on weekends. Milestones made this difficult.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;final-remarks&quot;&gt;Final Remarks&lt;/h2&gt;

&lt;p&gt;A possible criticism of this work is that the ability to decompose and tackle an un-scaffolded programming project is a core competency that students are expected to learn during intermediate programming courses, and they will no longer do so because “we did it for them”.&lt;/p&gt;

&lt;p&gt;Fundamentally, the problem with this is that we don’t really teach these skills at this stage in the curriculum. So we end up putting students through a “trial-by-fire” in these courses, and those who make it can continue on in the major. Ironically, these are the students who reach the later software engineering and capstone courses in which we do teach these skills.&lt;/p&gt;

&lt;p&gt;Milestones are by no means perfect, but we believe they help students (1) by making them practice a successful approach to large programming projects, and (2) by giving them the experience of successfully completing these projects, that they can then draw on in later courses. Effects of explicit milestones going into later courses is an open question.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I’d be surprised to learn that this is a novel practice. But I haven’t witnessed this at other institutions I’ve been affiliated with, and the literature review didn’t turn up anything in the context of intermediate project development. If your courses use milestones or something similar, how’s it going for you?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://doi.org/10.1145/2591062.2591159&quot;&gt;Radermacher, 2014&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-2909.133.1.65&quot;&gt;Steel, 2007&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://doi.wiley.com/10.1002/j.2168-9830.2001.tb00599.x&quot;&gt;Ponton, 2010&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:3:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/document/7017768/&quot;&gt;Song, 2014&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Withdrawing is not always a bad thing; maybe they just didn’t want to learn the subject. But computing faces a retention crisis due a variety of external and internal factors, and a student in a third-year course probably did want to complete the course. So here, we treat it as a Bad Thing™. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">This article was originally posted on my Medium blog on October 14, 2020.</summary></entry><entry><title type="html">Assessing Incremental Testing Practices and Their Impact on Project Outcomes</title><link href="https://ayaankazerouni.github.io/posts/assessing-incremental-testing" rel="alternate" type="text/html" title="Assessing Incremental Testing Practices and Their Impact on Project Outcomes" /><published>2020-07-07T00:00:00-07:00</published><updated>2020-07-07T00:00:00-07:00</updated><id>https://ayaankazerouni.github.io/posts/assessing-incremental-testing</id><content type="html" xml:base="https://ayaankazerouni.github.io/posts/assessing-incremental-testing">&lt;p&gt;&lt;small&gt;
&lt;em&gt;This article was originally posted on &lt;a href=&quot;https://ayaankazerouni.medium.com&quot;&gt;my Medium blog&lt;/a&gt; on July 7 2020.&lt;/em&gt;
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is a brief overview of the research paper “&lt;strong&gt;&lt;a href=&quot;/publications#sigcse2019paper”&quot;&gt;Assessing Incremental Testing Practices and Their Impact on Project Outcomes&lt;/a&gt;&lt;/strong&gt;, published at SIGCSE 2019. My co-authors were &lt;a href=&quot;https://people.cs.vt.edu/~shaffer&quot;&gt;Cliff Shaffer&lt;/a&gt;, &lt;a href=&quot;https://people.cs.vt.edu/~edwards&quot;&gt;Steve Edwards&lt;/a&gt;, and &lt;a href=&quot;https://people.cs.vt.edu/~fservant&quot;&gt;Francisco Servant&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Software testing is the most common method of ensuring the correctness of software. As students work on relatively long-running software projects, we would like to know if they are engaging with testing consistently through the life-cycle. The long-term goal is to provide students with feedback about their testing habits as they work on projects.&lt;/p&gt;

&lt;p&gt;This post is aimed at computing educators, researchers, and engineers.&lt;/p&gt;

&lt;p&gt;We examined the programming effort applied by students during (unsupervised) programming sessions as they worked on projects, and measured the proportion of that effort that was devoted to writing tests. This measurement is useful because it lets us avoid the “test-first” or “test-last” dichotomy and allowed for varying styles and levels of engagement with testing over time. It can also be easily measured in real-time, facilitating automated and adaptive formative feedback.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;h3 id=&quot;goal&quot;&gt;Goal&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;To assess a student’s software testing, not just their software tests&lt;/li&gt;
  &lt;li&gt;To understand how various levels of engagement with testing relate to project outcomes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;method&quot;&gt;Method&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Collect high-resolution project snapshot histories from consenting students’ IDEs and mine them for insight about their testing habits&lt;/li&gt;
  &lt;li&gt;Test the relationships between students’ testing habits and their eventual project correctness and test suite quality&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;findings&quot;&gt;Findings&lt;/h3&gt;
&lt;p&gt;Unsurprisingly, we found that when more of each session’s programming effort was devoted to testing, students produced solutions with higher correctness and test suites with higher condition coverage. We also found that project correctness was unrelated to whether students did their testing before or after writing the relevant solution code.&lt;/p&gt;

&lt;p&gt;Our findings suggest that the incremental nature of testing was more important than whether the student practiced “test-first” or “test-last” styles of development. The within-subjects nature of our experimental design hints that these relationships may be causal.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Students and new software engineering graduates often display poor testing ability and a disinclination to practice regular testing.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; It is now common practice to require unit tests to be submitted along with project solutions. But it is unclear if students are writing these tests incrementally as they work toward a solution, or if they are following the less desirable “code a lot, test a little” style of development.&lt;/p&gt;

&lt;p&gt;Learning a skill like incremental testing requires practice, and practice should be accompanied by feedback to maximise skill acquisition. But we cannot produce feedback about practice without observing it. We conducted a study in our third-year Data Structures &amp;amp; Algorithms course to (1) measure students’ adherence to incremental test writing as they worked on large, complex programming projects, and (2) understand the impact that their test writing practices had on project outcomes.&lt;/p&gt;

&lt;p&gt;We focused on addressing two challenges to the pedagogy of software testing:
First, existing testing feedback tends to focus on product rather than process. That is, assessments tend to be driven by “post-mortem” measures like code coverage, all-pairs execution, or (rarely) mutation coverage achieved by students’ submissions. Students’ adherence to test-oriented development processes as they produce those submissions is largely ignored.&lt;/p&gt;

&lt;p&gt;We addressed this by measuring the balance of students’ test writing vs. solution writing activities as they worked on their projects. If we can reliably measure students’ engagement with testing as they work on projects, we can provide formative feedback to help keep them on track in the short term, and help them form incremental testing habits in the long term.&lt;/p&gt;

&lt;p&gt;Second, there is a lack of agreement on what constitutes effective testing process. Numerous researchers have presented (often conflicting&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;) evidence about the effectiveness of test-driven development (TDD) and incremental test-last (ITL) styles of development. But these findings may not generalise to students learning testing practices, and the conflicting evidence muddies the issue of what exactly we should teach or prescribe.
We addressed this by avoiding the “TDD or not” dichotomy. Students’ (and indeed, professionals’) engagement with testing does not stay consistent over time, either in kind or in volume &lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. Therefore, we didn’t attempt to classify student work as following TDD or not. Instead, we measured the extent to which they balanced their test writing and solution writing activities for increments of work over the course of their projects. This allowed us to more faithfully represent and study their varying levels of engagement with testing as they worked toward solutions.&lt;/p&gt;

&lt;h2 id=&quot;measuring-incremental-test-writing&quot;&gt;Measuring Incremental Test Writing&lt;/h2&gt;

&lt;h3 id=&quot;context-and-data-collection&quot;&gt;Context and data collection&lt;/h3&gt;
&lt;p&gt;Students in our context are working on software projects that are larger and more complex than what they have encountered in previous courses. Success usually necessitates adherence to disciplined software process, including time management and regular testing. We studied roughly 150 students working on 4 programming assignments over a semester (~3.5 month period).&lt;/p&gt;

&lt;p&gt;We used an &lt;a href=&quot;https://github.com/web-cat/eclipse-plugins-importer-exporter/tree/DevEventTrackerAddition&quot;&gt;Eclipse plugin&lt;/a&gt; to automatically collect frequent snapshots of students’ projects as they worked toward solutions. This snapshot history allowed us to paint a rich picture of a project’s evolution. In particular, it let us look at how the test code and solution code for a project emerged over time.&lt;/p&gt;

&lt;h3 id=&quot;proposed-measurements-of-testing-effort&quot;&gt;Proposed measurements of testing effort&lt;/h3&gt;
&lt;p&gt;Using these data, we measured the balance and sequence of students’ test writing effort with respect to their solution writing effort. I describe these measurements below.&lt;/p&gt;

&lt;p&gt;Consider the following figure, which shows an example sequence of developer activity created from synthetic data. Colours indicate methods in the project; solid and shaded blocks are solution and test code, respectively; and groups of blocks indicate work sessions.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/assessing-incremental-testing/example-dev-activity.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/assessing-incremental-testing/example-dev-activity.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;An example sequence of developer activity (synthetic data).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;We can derive measurements of balance and sequence of testing with this synthetic data in mind.
The measures are summarised in the next figure.&lt;/p&gt;

&lt;p&gt;In terms of &lt;strong&gt;balance&lt;/strong&gt;, we considered testing effort in terms of &lt;em&gt;space&lt;/em&gt; (methods in the project), &lt;em&gt;time&lt;/em&gt; (work sessions), &lt;em&gt;both&lt;/em&gt;, or &lt;em&gt;neither&lt;/em&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Neither&lt;/strong&gt;: how much total testing took place over the course of the project and its lifecycle? (POB in the figure below)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Space only&lt;/strong&gt;: how much testing took place for each method in the project? (MOB)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Time only&lt;/strong&gt;: how much testing took place during each work session? (PSB)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Both time and space&lt;/strong&gt;: how much testing took place for each method during each work session? (MSB)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each measurement is a proportion, i.e., the proportion of all code — written in a work session or for a method or on the entire project — that was test code. So if a student wrote 100 LoC in a work session, and 20 of them were test code, the proportion for that work session would be 0.2.&lt;/p&gt;

&lt;p&gt;In terms of &lt;strong&gt;sequence&lt;/strong&gt;, we measured the extent to which students tended to write test code before finalising the solution code under test (MOS below).&lt;br /&gt;
This was measured as the proportion of test code devoted to a method that was written before the method was finalised (i.e., before it was changed for the last time).&lt;/p&gt;

&lt;p&gt;Note that this is different from measuring adherence to “TDD or not”.
Instead of classifying a student’s work (in a work session, or on a method, etc.) as strictly test-first or test-last, we measure this concept on a continuous scale.
This allows a more nuanced discussion of students’ tendencies to write test code earlier or later with respect to the solution code that is being tested.&lt;/p&gt;

&lt;p&gt;Measurements are depicted in the figure below. All measurements were aggregated as medians for each project.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/assessing-incremental-testing/metrics.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/assessing-incremental-testing/metrics.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Measurements to be derived from a programming activity stream. Each row depicts a different way of aggregating the events from the figure above.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;findings-1&quot;&gt;Findings&lt;/h2&gt;

&lt;p&gt;With these measurements in hand, we are able to examine students’ incremental testing practices and their impacts on project outcomes.&lt;/p&gt;

&lt;h3 id=&quot;to-what-extent-did-students-practice-incremental-testing&quot;&gt;To what extent did students practice incremental testing?&lt;/h3&gt;

&lt;p&gt;Using the measurements we described, we can make observations about how students distributed their testing effort as they worked on projects.&lt;/p&gt;

&lt;p&gt;The measurements are summarised in the figure below. The first four box-plots (in blue) represent measures of the balance of test writing effort. The fifth box-plot (in orange) represents proportion of test writing effort devoted before the relevant solution code was finalised.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/assessing-incremental-testing/boxplots-balance-sequence.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/assessing-incremental-testing/boxplots-balance-sequence.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Distributions of testing effort measurements described above.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Our findings were as follows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Balance of testing effort&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Students tended to devote about 25% of their total code writing effort to writing test code &lt;em&gt;(POB)&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Within individual work sessions, a majority of students devoted less than 20% of their coding effort to writing tests &lt;em&gt;(PSB)&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;The median method seemed to received a considerable amount of testing effort (&lt;em&gt;MOB&lt;/em&gt;, &lt;em&gt;MSB&lt;/em&gt;), possibly attributable to the way we tied solution methods and test methods together &lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The lower proportions of testing effort observed per work session, relative to the total project testing effort, suggests that some sessions tend to see more testing effort than others. Prior work suggests that this increased testing tends to take place toward the end of the project life-cycle, to satisfy condition coverage requirements imposed on students as part of the programming assignments.&lt;/p&gt;

&lt;p&gt;The lower proportions of testing effort observed per work session, relative to the total project testing effort, suggests that some sessions tend to see more testing effort than others. &lt;a href=&quot;https://ayaankazerouni.github.io/assets/publications/quantifying-incremental-development-procrastination.pdf&quot;&gt;Prior work&lt;/a&gt; suggests that this increased testing tends to take place toward the end of the project life-cycle, to satisfy condition coverage requirements imposed on students as part of the programming assignments.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sequence of testing effort&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In an overwhelming majority of submissions (85%), students tended to do their testing after the relevant solution methods were finalised (&lt;em&gt;MOS&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-did-project-outcomes-relate-to-the-balance-and-sequence-of-test-writing-activities&quot;&gt;How did project outcomes relate to the balance and sequence of test writing activities?&lt;/h3&gt;

&lt;p&gt;We measured the relationship between the measurements described above and two outcomes of interest:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Correctness&lt;/em&gt;, measured by an instructor-written oracle of reference tests&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Code coverage&lt;/em&gt;, measured as the condition coverage achieved by the student’s own test suite&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We used linear mixed-effects models, with the outcome of interest as a dependent variable and the testing measurements as the independent variables.
This allowed us to tease out the variance in project outcomes that was explained by traits inherent to individual students.&lt;/p&gt;

&lt;p&gt;We found that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Students produced higher quality solutions and tests when they devoted a higher proportion of their programming effort in each session to writing tests&lt;/li&gt;
  &lt;li&gt;Whether this testing occurred before or after the relevant solution code was written was irrelevant to project correctness&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We also found a &lt;em&gt;negative&lt;/em&gt; relationship between doing more testing before finalising solution code and condition coverage scores.
We do not think this means that &lt;em&gt;testing first is bad&lt;/em&gt;—more likely this is an effect of students adding tests to nearly complete projects to drive up condition coverage, which made up part of their grade.
Incentives beget behaviours!&lt;/p&gt;

&lt;p&gt;Note that, after teasing out the variance explained by inherent variability in the students (conditional \(R^2\) in the paper), our measurements explained an ultimately small percentage of variance in project correctness and condition coverage (marginal \(R^2\) in the paper).
More variance in outcomes can possibly be explained by any number of unaccounted-for factors.
It is also possible that projects in the Data Structures course we studied didn’t “hit the right switches” in terms of depending on regular testing for success.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;Our findings largely support the conventional wisdom about the virtues of regular software testing.
We did not find support for the notion that writing tests first leads to better project outcomes.&lt;/p&gt;

&lt;p&gt;Traits or situations inherent to individual students are unlikely to have affected our results.
Students’ differing behaviours &lt;em&gt;and&lt;/em&gt; outcomes could both be symptoms of some other unknown factors (e.g., prior programming experience, differing demands on time).
Therefore, we used &lt;em&gt;within-subjects&lt;/em&gt; comparisons—i.e., assignments served as repeated measures for each student.
Each student’s work on a given project was compared to their own work on other projects, and differences in testing practices and project outcomes were observed.&lt;/p&gt;

&lt;p&gt;The primary contribution of this work is that we are able to measure a student’s adherence to these practices with some lead time before final project deadlines.
The short-term benefit of this is that we can provide feedback to students “before the damage is done”, i.e., before they face the consequences of poor testing practices that we have measured and observed.&lt;/p&gt;

&lt;p&gt;In the long-term, we think that formative feedback about testing, delivered as students work on projects, can help them to form disciplined test-oriented development habits.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/2445196.2445351&quot;&gt;Radermacher, 2013&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/7592412?casa_token=EairhmqPPOgAAAAA:ag2Z44va8LgKn-K5NhAhDLFyn-nmTRksrVGQTMvB2qftTlfS94O1FZZyClPDUvT8qM011tfC_ls&quot;&gt;Fucci, 2017&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/1159733.1159787&quot;&gt;Bhat, 2006&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://inventitech.com/assets/publications/2017_beller_gousios_panichella_amann_proksch_zaidman_developer_testing_in_the_ide_patterns_beliefs_and_behavior.pdf&quot;&gt;Beller, 2015&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://inventitech.com/assets/publications/2017_beller_gousios_panichella_amann_proksch_zaidman_developer_testing_in_the_ide_patterns_beliefs_and_behavior.pdf&quot;&gt;Beller, 2015a&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Solution methods were tied to test methods if they were directly invoked in the test method. So whether or not an invoked method was the “focal method” of the test, it was treated as “being tested”. This could have inflated results for methods that were commonly used to set up test cases. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">This article was originally posted on my Medium blog on July 7 2020.</summary></entry><entry><title type="html">Developing Procrastination Feedback for Student Software Developers</title><link href="https://ayaankazerouni.github.io/posts/procrastination-feedback" rel="alternate" type="text/html" title="Developing Procrastination Feedback for Student Software Developers" /><published>2020-04-17T00:00:00-07:00</published><updated>2020-04-17T00:00:00-07:00</updated><id>https://ayaankazerouni.github.io/posts/procrastination-feedback</id><content type="html" xml:base="https://ayaankazerouni.github.io/posts/procrastination-feedback">&lt;p&gt;&lt;small&gt;
&lt;em&gt;This article originally appeared on &lt;a href=&quot;ayaankazerouni.medium.com&quot;&gt;my Medium blog&lt;/a&gt; on April 17, 2020.&lt;/em&gt;
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is a brief overview of the following research papers by myself, &lt;a href=&quot;https://people.cs.vt.edu/~edwards/&quot;&gt;Steve Edwards&lt;/a&gt;, and &lt;a href=&quot;https://people.cs.vt.edu/~shaffer/&quot;&gt;Cliff Shaffer&lt;/a&gt;:&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;&lt;strong&gt;&lt;a href=&quot;/publications/iticse2017paper&quot;&gt;DevEventTracker: Tracking Development Events to Assess Incremental Development and Procrastination&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt; (with T. Simin Hall), published at ITiCSE 2017, and&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;&lt;strong&gt;&lt;a href=&quot;/publications/icer2017paper&quot;&gt;Quantifying Incremental Development Practices and Their Relationship to Procrastination&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;, published at ICER 2017&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am summarising these papers together because they are closely related.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;We would like to determine the effectiveness of the time management practices displayed by students as they work on large and complex programming projects for the first time. We used qualitative data (obtained from interviews with students) and quantitative data (obtained using IDE logging infrastructure) to characterise their software development habits, and we analysed their relationships with project outcomes like correctness, total time taken, and the project’s early or late status.&lt;/p&gt;

&lt;p&gt;When students worked earlier and more often, they produced projects that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;were more correct,&lt;/li&gt;
  &lt;li&gt;were completed earlier,&lt;/li&gt;
  &lt;li&gt;took no more or less time to complete&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So working earlier and more often doesn’t seem to be giving the student more time to complete projects, just more &lt;em&gt;constructive&lt;/em&gt; time.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Software development is a skill. Like any skill, it requires practice and feedback in order to develop. Ideally, this feedback should formative — delivered as students work on projects. However, in education contexts, assessments of software projects are driven by “after-the-fact” qualities like correctness, code coverage, code style, etc. In the papers listed above, my co-authors and I present methods to characterise students’ time management habits as they work on large and complex projects. The goal is to use this information to formulate formative feedback about their development practices.&lt;/p&gt;

&lt;h2 id=&quot;observing-the-development-process&quot;&gt;Observing the development process&lt;/h2&gt;

&lt;p&gt;To properly assess a ~30-hour programming process, we need to be able to observe it. We developed an Eclipse plugin that emits events for various in-IDE actions, including:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;executions&lt;/li&gt;
  &lt;li&gt;compilations&lt;/li&gt;
  &lt;li&gt;file saves&lt;/li&gt;
  &lt;li&gt;line-level edits&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We use these data to capture, characterise, and determine the effectiveness of the software development process undertaken by students. This process involved ingesting a large (ish) volume of data and turning it into an objective measurement of some aspect of the programming process (in this case, procrastination).&lt;/p&gt;

&lt;h2 id=&quot;when-do-students-work-on-software-projects&quot;&gt;When do students work on software projects?&lt;/h2&gt;

&lt;p&gt;We set out to quantitatively measure the extent to which &lt;strong&gt;procrastination&lt;/strong&gt; manifests as students work on software projects. We look at the work done by students as a distribution of work days, from the first day the student worked on the project until the last day, typically the day of the project deadline. The value for each work day is the amount of observable “work” that was put in on the project — the number of character code edits. The mean of this distribution gives us the “average day” on which students tended to work on the project. If we measure this in terms of &lt;em&gt;days until the deadline&lt;/em&gt;, then a higher number indicates that more work was done earlier, and a lower number indicates that more work was done closer to the deadline.&lt;/p&gt;

&lt;p&gt;As an example, consider the figure below, which shows how a real student distributed their work across the days on which they worked on a project.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/procrastination-feedback/tm-early-often.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/procrastination-feedback/tm-early-often.png&quot; alt=&quot;&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;The mean edit time for a student, drawn from real data.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- A bar chart showing the amount of work put in by a student on each day from August 28 to September 14. --&gt;
&lt;p&gt;The red line on September 14 indicates the project deadline, and the black line on September 8 indicates the student’s “mean edit time”, which is 6 days before the deadline. A sizeable portion of work was done within the period of September 1 to September 8, and daily work was much higher during the last three days of the project lifecycle. This leads the mean edit time to be roughly in the middle of those time periods. The student’s score is therefore sensitive to not only the days on which was done, but also to the amount of work that was done on those days. Since this is simply a mean edit time, we can measure this with solution code, test code, or both.&lt;/p&gt;

&lt;p&gt;We might also have measured the median edit time (i.e., on what day was half the work done on a project?). However, we opted for the mean since it is more sensitive to outliers, which are important when measuring procrastination (e.g., large amounts of code being written toward the end of a project timeline).&lt;/p&gt;

&lt;p&gt;The figure below indicates distributions of the mean edit time for solution code and for test code, across all project implementations.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/procrastination-feedback/solution-test-early-often-dists.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/procrastination-feedback/solution-test-early-often-dists.png&quot; alt=&quot;Two box-and-whisker plots which show the mean edit times for solution code and test code.&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;On average, students tended to write code fewer than 10 days before the project deadline.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- On average, students tended to write code fewer than 10 days before the project deadline. --&gt;
&lt;p&gt;This figure tells us that students tended to work rather close to the deadline, even though they were given about 30 days to work on projects. Similar distributions of mean times were observed for solution code (\(\mu=8.48, \sigma=6.44\)), test code (\(\mu=7.78, \sigma=7.04\)), program executions (\(\mu=8.86, \sigma=8.82\)), and test executions (\(\mu=7.09, \sigma=7.10\)). Test editing and launching tends to occur slightly closer to the project deadline, but this difference appears to be negligible.&lt;/p&gt;

&lt;h2 id=&quot;how-valid-is-our-measurement&quot;&gt;How valid is our measurement?&lt;/h2&gt;

&lt;p&gt;The measurement described above is simple enough: it’s just a mean. Still, it is worth investigating whether it measures what we think it measures, i.e., the extent to which procrastination manifests on a software project. There is no readily-available “ground truth” against which one can test such a measurement. Therefore, we interviewed students in depth about their development experiences on two such assignments, and compared their responses with our measurements. Interviewees were given our measurements at the end of the interview, and we determined if they matched students’ expectations.&lt;/p&gt;

&lt;p&gt;In general, students felt that our measurements were accurate. Additionally, students believed that feedback driven by a measure such as this could help them stay on track on future programming projects. They stated unconditionally that they would make more of an effort to improve their programming practice if they were given feedback about their process between assignments.&lt;/p&gt;

&lt;h2 id=&quot;can-this-measurement-explain-differences-in-project-outcomes&quot;&gt;Can this measurement explain differences in project outcomes?&lt;/h2&gt;

&lt;p&gt;A primary thesis of these papers was that different software development habits can explain differences in software project outcomes for intermediate-to-advanced student software developers. With our measures and their qualitative evaluations in hand, we set out to quantitatively examine their relationships with the following project outcomes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Project correctness&lt;/strong&gt;, measured as the percentage of instructor-written reference tests passed,&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Time of completion&lt;/strong&gt;, measured as the number of hours before the deadline the project was completed, and&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Total time spent&lt;/strong&gt;, measured by adding up the lengths of all work sessions spent on the project&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We used within-subjects comparisons to make inferences, allowing us to control for traits unique to individual students. Different students’ behaviours &lt;em&gt;and&lt;/em&gt; outcomes could be symptoms of some other unknown factor (e.g., differing course loads or prior experience), making such inferences weaker. To test for relationships with the outcome variables, we used an ANCOVA with repeated measures for each student. Students were subjects, and assignments served as repeated measures (with unequal variances), allowing within-subjects comparisons. In other words, each student’s software development habits were measured repeatedly (assignments), and differences in outcomes for the same student were analysed.&lt;/p&gt;

&lt;p&gt;Results are summarised below.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;When students worked earlier and more often, they tended to produce programs with higher correctness.&lt;/strong&gt; To illustrate this, we split the dataset roughly into half: those projects that had “solved” the assigned problem (53%), and those that had not (47%). The figure below shows the difference in edit mean times between these populations.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/procrastination-feedback/solution-early-often-by-solved.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/procrastination-feedback/solution-early-often-by-solved.png&quot; alt=&quot;Two box-and-whisker plots showing the mean edit time for solved and unsolved projects.&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Comparison of solution edit times between projects that correctly solved an assignment, and those that did not.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;When students worked earlier and more often, they tended to finish their projects earlier.&lt;/strong&gt; This is so intuitive, it’s almost tautological. It is encouraging that the measurement is able to discriminate between early and late project submissions.&lt;/p&gt;

&lt;figure&gt;

  &lt;a href=&quot;/assets/posts/images/procrastination-feedback/solution-early-often-by-on-time-status.png&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;/assets/posts/images/procrastination-feedback/solution-early-often-by-on-time-status.png&quot; alt=&quot;Two box-and-whisker plots showing the mean edit time for late and on-time submissions.&quot; /&gt;
  &lt;/a&gt;
  &lt;figcaption&gt;Comparison of solution edit times between on-time and late submissions.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Finally, &lt;strong&gt;there was no relationship between total amount of time spent on the project and the solution edit mean time.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;final-remarks&quot;&gt;Final Remarks&lt;/h2&gt;

&lt;p&gt;The important takeaway from these papers is not the revelation that &lt;em&gt;procrastination = bad&lt;/em&gt;. It is that we can reliably identify when procrastination is taking place on software projects. If we can do this during a project timeline, i.e., while the student is working on it, we may be able to intervene and help them adjust their programming behaviours before they face the consequences of procrastination.&lt;/p&gt;</content><author><name></name></author><summary type="html">This article originally appeared on my Medium blog on April 17, 2020.</summary></entry></feed>